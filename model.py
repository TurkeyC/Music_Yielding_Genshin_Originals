import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, LambdaCallback
import numpy as np
import json
import time
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import threading

class HoyoMusicGenerator:
    def __init__(self, vocab_size, seq_length, embedding_dim=256, lstm_units=512):
        self.vocab_size = vocab_size
        self.seq_length = seq_length
        self.embedding_dim = embedding_dim
        self.lstm_units = lstm_units
        self.model = None
        self.training_history = {}
        self.training_start_time = None
        self.estimated_time_remaining = None
        
    def build_model(self):
        """æ„å»ºé’ˆå¯¹HoyoMusicä¼˜åŒ–çš„LSTMæ¨¡å‹"""
        model = Sequential([
            # åµŒå…¥å±‚ - ä¸ºABCè®°è°±ä¼˜åŒ–
            Embedding(
                self.vocab_size, 
                self.embedding_dim, 
                input_length=self.seq_length,
                mask_zero=True,
                name='embedding'
            ),
            
            # ç¬¬ä¸€å±‚LSTM - æ•è·çŸ­æœŸæ¨¡å¼
            LSTM(
                self.lstm_units, 
                return_sequences=True, 
                dropout=0.3, 
                recurrent_dropout=0.3,
                name='lstm_1'
            ),
            BatchNormalization(name='bn_1'),
            
            # ç¬¬äºŒå±‚LSTM - æ•è·ä¸­æœŸæ¨¡å¼
            LSTM(
                self.lstm_units, 
                return_sequences=True, 
                dropout=0.3, 
                recurrent_dropout=0.3,
                name='lstm_2'
            ),
            BatchNormalization(name='bn_2'),
            
            # ç¬¬ä¸‰å±‚LSTM - æ•è·é•¿æœŸä¾èµ–
            LSTM(
                self.lstm_units, 
                dropout=0.3, 
                recurrent_dropout=0.3,
                name='lstm_3'
            ),
            BatchNormalization(name='bn_3'),
            
            # å…¨è¿æ¥å±‚
            Dense(self.lstm_units, activation='relu', name='dense_1'),
            Dropout(0.5),
            
            Dense(self.lstm_units // 2, activation='relu', name='dense_2'),
            Dropout(0.3),
            
            # è¾“å‡ºå±‚
            Dense(self.vocab_size, activation='softmax', name='output')
        ])
        
        # ä½¿ç”¨è‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–å™¨
        optimizer = Adam(
            learning_rate=0.001,
            beta_1=0.9,
            beta_2=0.999,
            epsilon=1e-8
        )
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy', 'sparse_top_k_categorical_accuracy']
        )
        
        self.model = model
        return model
    
    def load_model_for_incremental_training(self, model_path, learning_rate=0.0005):
        """åŠ è½½ç°æœ‰æ¨¡å‹è¿›è¡Œå¢é‡è®­ç»ƒ"""
        print(f"ğŸ”„ åŠ è½½ç°æœ‰æ¨¡å‹è¿›è¡Œå¢é‡è®­ç»ƒ: {model_path}")
        
        try:
            # åŠ è½½ç°æœ‰æ¨¡å‹
            self.model = load_model(model_path)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # é™ä½å­¦ä¹ ç‡ä»¥è¿›è¡Œå¢é‡è®­ç»ƒ
            new_optimizer = Adam(
                learning_rate=learning_rate,
                beta_1=0.9,
                beta_2=0.999,
                epsilon=1e-8
            )
            
            # é‡æ–°ç¼–è¯‘æ¨¡å‹
            self.model.compile(
                optimizer=new_optimizer,
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy', 'sparse_top_k_categorical_accuracy']
            )
            
            print(f"ğŸ¯ å¢é‡è®­ç»ƒå­¦ä¹ ç‡è®¾ç½®ä¸º: {learning_rate}")
            
            # åŠ è½½å†å²è®­ç»ƒä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            self.load_training_history()
            
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            print("ğŸ”§ å°†åˆ›å»ºæ–°æ¨¡å‹...")
            self.build_model()
            return False
    
    def save_training_history(self, history_path='models/training_history.json'):
        """ä¿å­˜è®­ç»ƒå†å²"""
        try:
            with open(history_path, 'w') as f:
                json.dump(self.training_history, f, indent=2)
            print(f"ğŸ“Š è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_path}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è®­ç»ƒå†å²å¤±è´¥: {e}")
    
    def load_training_history(self, history_path='models/training_history.json'):
        """åŠ è½½è®­ç»ƒå†å²"""
        try:
            with open(history_path, 'r') as f:
                self.training_history = json.load(f)
            print(f"ğŸ“ˆ è®­ç»ƒå†å²å·²åŠ è½½ï¼ŒåŒ…å« {len(self.training_history.get('loss', []))} ä¸ªepoch")
        except FileNotFoundError:
            print("ğŸ“ æœªæ‰¾åˆ°è®­ç»ƒå†å²æ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°çš„å†å²è®°å½•")
            self.training_history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}
        except Exception as e:
            print(f"âš ï¸ åŠ è½½è®­ç»ƒå†å²å¤±è´¥: {e}")
            self.training_history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}
    
    def estimate_training_time(self, total_samples, batch_size, epochs, validation_split=0.2):
        """é¢„ä¼°è®­ç»ƒæ—¶é—´"""
        # ä¼°ç®—æ¯ä¸ªbatchçš„è®­ç»ƒæ—¶é—´ï¼ˆåŸºäºç»éªŒå€¼ï¼‰
        samples_per_epoch = int(total_samples * (1 - validation_split))
        batches_per_epoch = (samples_per_epoch + batch_size - 1) // batch_size
        
        # åŸºäºæ¨¡å‹å¤æ‚åº¦ä¼°ç®—æ—¶é—´ï¼ˆç§’/batchï¼‰
        base_time_per_batch = 0.1  # RTX4060çš„åŸºå‡†æ—¶é—´
        
        # æ ¹æ®æ¨¡å‹å‚æ•°è°ƒæ•´
        complexity_factor = (self.lstm_units / 512) * (self.seq_length / 100)
        time_per_batch = base_time_per_batch * complexity_factor
        
        # éªŒè¯æ—¶é—´ï¼ˆé€šå¸¸æ¯”è®­ç»ƒå¿«ï¼‰
        validation_samples = int(total_samples * validation_split)
        validation_batches = (validation_samples + batch_size - 1) // batch_size
        validation_time_per_epoch = validation_batches * time_per_batch * 0.3
        
        # æ€»æ—¶é—´ä¼°ç®—
        training_time_per_epoch = batches_per_epoch * time_per_batch
        total_time_per_epoch = training_time_per_epoch + validation_time_per_epoch
        total_estimated_time = total_time_per_epoch * epochs
        
        return {
            'total_estimated_seconds': total_estimated_time,
            'time_per_epoch': total_time_per_epoch,
            'batches_per_epoch': batches_per_epoch,
            'time_per_batch': time_per_batch
        }
    
    def create_time_estimation_callback(self, time_estimates):
        """åˆ›å»ºæ—¶é—´ä¼°ç®—å›è°ƒå‡½æ•°"""
        def on_epoch_end(epoch, logs):
            if self.training_start_time:
                elapsed_time = time.time() - self.training_start_time
                epochs_completed = epoch + 1
                
                if epochs_completed > 0:
                    avg_time_per_epoch = elapsed_time / epochs_completed
                    remaining_epochs = time_estimates['total_epochs'] - epochs_completed
                    self.estimated_time_remaining = avg_time_per_epoch * remaining_epochs
                    
                    # æ›´æ–°é¢„ä¼°å®Œæˆæ—¶é—´
                    completion_time = datetime.now() + timedelta(seconds=self.estimated_time_remaining)
                    
                    print(f"â±ï¸  Epoch {epochs_completed}: å‰©ä½™æ—¶é—´ {self.format_time(self.estimated_time_remaining)}")
                    print(f"ğŸ“… é¢„è®¡å®Œæˆæ—¶é—´: {completion_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        return LambdaCallback(on_epoch_end=on_epoch_end)
    
    def format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.0f}ç§’"
        elif seconds < 3600:
            minutes = seconds // 60
            remaining_seconds = seconds % 60
            return f"{minutes:.0f}åˆ†{remaining_seconds:.0f}ç§’"
        else:
            hours = seconds // 3600
            remaining_minutes = (seconds % 3600) // 60
            return f"{hours:.0f}å°æ—¶{remaining_minutes:.0f}åˆ†é’Ÿ"
    
    def get_callbacks(self, model_save_path, time_estimates=None):
        """è·å–è®­ç»ƒå›è°ƒå‡½æ•°"""
        callbacks = [
            ModelCheckpoint(
                filepath=model_save_path,
                monitor='val_loss',
                save_best_only=True,
                save_weights_only=False,
                mode='min',
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=0.0001,
                verbose=1
            ),
            EarlyStopping(
                monitor='val_loss',
                patience=15,
                restore_best_weights=True,
                verbose=1
            )
        ]
        
        # æ·»åŠ æ—¶é—´ä¼°ç®—å›è°ƒ
        if time_estimates:
            callbacks.append(self.create_time_estimation_callback(time_estimates))
        
        return callbacks
    
    def train(self, X, y, epochs=100, batch_size=32, validation_split=0.2, 
              model_save_path='models/hoyomusic_generator.h5', is_incremental=False):
        """è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒå¢é‡è®­ç»ƒï¼‰"""
        
        print(f"ğŸš€ å¼€å§‹{'å¢é‡' if is_incremental else ''}è®­ç»ƒ...")
        
        # å¦‚æœä¸æ˜¯å¢é‡è®­ç»ƒä¸”æ¨¡å‹ä¸å­˜åœ¨ï¼Œåˆ™æ„å»ºæ–°æ¨¡å‹
        if not is_incremental and self.model is None:
            self.build_model()
        
        print(f"ğŸµ HoyoMusicç”Ÿæˆå™¨æ¨¡å‹æ‘˜è¦:")
        self.model.summary()
        
        # é¢„ä¼°è®­ç»ƒæ—¶é—´
        time_estimates = self.estimate_training_time(len(X), batch_size, epochs, validation_split)
        time_estimates['total_epochs'] = epochs
        
        print(f"\nâ±ï¸  è®­ç»ƒæ—¶é—´é¢„ä¼°:")
        print(f"  - æ¯ä¸ªepoché¢„ä¼°: {self.format_time(time_estimates['time_per_epoch'])}")
        print(f"  - æ€»è®­ç»ƒæ—¶é—´é¢„ä¼°: {self.format_time(time_estimates['total_estimated_seconds'])}")
        print(f"  - æ¯æ‰¹æ¬¡æ—¶é—´: {time_estimates['time_per_batch']:.2f}ç§’")
        print(f"  - æ¯ä¸ªepochæ‰¹æ¬¡æ•°: {time_estimates['batches_per_epoch']}")
        
        completion_time = datetime.now() + timedelta(seconds=time_estimates['total_estimated_seconds'])
        print(f"  - é¢„è®¡å®Œæˆæ—¶é—´: {completion_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
        self.training_start_time = time.time()
        
        # è·å–å›è°ƒå‡½æ•°
        callbacks = self.get_callbacks(model_save_path, time_estimates)
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            X, y,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=validation_split,
            callbacks=callbacks,
            verbose=1,
            shuffle=True
        )
        
        # æ›´æ–°è®­ç»ƒå†å²
        if is_incremental and self.training_history:
            # åˆå¹¶å†å²è®°å½•
            for key in history.history:
                if key in self.training_history:
                    self.training_history[key].extend(history.history[key])
                else:
                    self.training_history[key] = history.history[key]
        else:
            self.training_history = history.history
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.save_training_history()
        
        # è®¡ç®—å®é™…è®­ç»ƒæ—¶é—´
        actual_training_time = time.time() - self.training_start_time
        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ• å®é™…è®­ç»ƒæ—¶é—´: {self.format_time(actual_training_time)}")
        print(f"ğŸ“ˆ æœ€ç»ˆéªŒè¯æŸå¤±: {history.history['val_loss'][-1]:.4f}")
        print(f"ğŸ¯ æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {history.history['val_accuracy'][-1]:.4f}")
        
        return history
    
    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        self.model = load_model(model_path)
        print(f"HoyoMusicæ¨¡å‹å·²ä» {model_path} åŠ è½½")
    
    def generate_music(self, seed_text, char_to_int, int_to_char, length=800, temperature=0.8):
        """ç”ŸæˆHoyoMusicé£æ ¼çš„éŸ³ä¹"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½æˆ–æœªè®­ç»ƒ")
        
        # å‡†å¤‡ç§å­åºåˆ—
        seed_sequence = [char_to_int.get(char, 0) for char in seed_text[-self.seq_length:]]
        
        # å¦‚æœç§å­åºåˆ—å¤ªçŸ­ï¼Œç”¨ç©ºæ ¼å¡«å……
        while len(seed_sequence) < self.seq_length:
            seed_sequence.insert(0, char_to_int.get(' ', 0))
        
        generated_text = seed_text
        
        # ç”ŸæˆéŸ³ä¹
        for i in range(length):
            # é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦
            x = np.array([seed_sequence])
            predictions = self.model.predict(x, verbose=0)[0]
            
            # åº”ç”¨æ¸©åº¦å‚æ•°è¿›è¡Œé‡‡æ ·
            predictions = np.log(predictions + 1e-8) / temperature
            exp_preds = np.exp(predictions)
            predictions = exp_preds / np.sum(exp_preds)
            
            # é‡‡æ ·ä¸‹ä¸€ä¸ªå­—ç¬¦
            next_char_idx = np.random.choice(len(predictions), p=predictions)
            next_char = int_to_char[next_char_idx]
            
            generated_text += next_char
            
            # æ›´æ–°ç§å­åºåˆ—
            seed_sequence = seed_sequence[1:] + [next_char_idx]
            
            # å¦‚æœç”Ÿæˆäº†å®Œæ•´çš„æ›²å­æ ‡è®°ï¼Œå¯ä»¥é€‰æ‹©åœæ­¢
            if i > 100 and generated_text.count('X:') > 3:  # ç”Ÿæˆäº†å¤šé¦–æ›²å­
                break
        
        return generated_text
    
    def generate_hoyomusic_style(self, region="Mondstadt", length=600, temperature=0.8, char_to_int=None, int_to_char=None):
        """ç”Ÿæˆç‰¹å®šåœ°åŒºé£æ ¼çš„åŸç¥éŸ³ä¹"""
        
        # ä¸åŒåœ°åŒºçš„ç§å­æ¨¡æ¿
        region_seeds = {
            "Mondstadt": "X:1\nT:Mondstadt Breeze\nC:Generated by AI\nM:4/4\nL:1/8\nK:C major\n",
            "Liyue": "X:1\nT:Liyue Harbor\nC:Generated by AI\nM:4/4\nL:1/8\nK:A minor\n",
            "Inazuma": "X:1\nT:Inazuma Thunder\nC:Generated by AI\nM:4/4\nL:1/8\nK:D major\n",
            "Sumeru": "X:1\nT:Sumeru Forest\nC:Generated by AI\nM:6/8\nL:1/8\nK:G major\n",
            "Fontaine": "X:1\nT:Fontaine Waters\nC:Generated by AI\nM:3/4\nL:1/4\nK:F major\n"
        }
        
        seed = region_seeds.get(region, region_seeds["Mondstadt"])
        
        return self.generate_music(seed, char_to_int, int_to_char, length, temperature)