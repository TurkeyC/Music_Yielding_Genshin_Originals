#!/usr/bin/env python3
"""
HoyoMusicç”Ÿæˆå™¨ - æ€§èƒ½åŸºå‡†æµ‹è¯•
å¯¹æ¯”ä¸åŒé…ç½®ä¸‹çš„è®­ç»ƒå’Œç”Ÿæˆæ€§èƒ½
"""

import os
import sys
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° sys.path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import time
import torch
import numpy as np
from model import HoyoMusicGenerator
from data_processor import HoyoMusicDataProcessor
import matplotlib.pyplot as plt
# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾

def benchmark_model_sizes():
    """æµ‹è¯•ä¸åŒæ¨¡å‹å¤§å°çš„æ€§èƒ½"""
    print("ğŸ”¬ æ¨¡å‹å¤§å°æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    configs = [
        {"name": "å°å‹", "embedding": 64, "lstm": 128, "seq_len": 50},
        {"name": "ä¸­å‹", "embedding": 128, "lstm": 256, "seq_len": 100},
        {"name": "å¤§å‹", "embedding": 256, "lstm": 512, "seq_len": 120},
        {"name": "è¶…å¤§", "embedding": 512, "lstm": 1024, "seq_len": 150},
    ]
    
    results = []
    
    for config in configs:
        print(f"\nğŸ“Š æµ‹è¯• {config['name']} æ¨¡å‹...")
        
        try:
            # åˆ›å»ºæ¨¡å‹
            start_time = time.time()
            generator = HoyoMusicGenerator(
                vocab_size=100,
                seq_length=config['seq_len'],
                embedding_dim=config['embedding'],
                lstm_units=config['lstm']
            )
            generator.build_model()
            build_time = time.time() - start_time
            
            # æ¨¡å‹å¤§å°
            param_count = generator.get_model_size()
            
            # è®­ç»ƒæ€§èƒ½æµ‹è¯•
            batch_size = 16
            X = np.random.randint(0, 100, (batch_size, config['seq_len']))
            y = np.random.randint(0, 100, (batch_size,))
            
            # é¢„çƒ­
            for _ in range(3):
                generator.train_step(X, y)
            
            # æµ‹è¯•è®­ç»ƒé€Ÿåº¦
            start_time = time.time()
            for _ in range(10):
                loss = generator.train_step(X, y)
            train_time = (time.time() - start_time) / 10
            
            # æµ‹è¯•ç”Ÿæˆé€Ÿåº¦
            seed = np.random.randint(0, 100, config['seq_len'])
            start_time = time.time()
            generated = generator.generate_sequence(seed, length=50)
            gen_time = time.time() - start_time
            
            result = {
                'name': config['name'],
                'params': param_count,
                'build_time': build_time,
                'train_time': train_time,
                'gen_time': gen_time,
                'config': config
            }
            results.append(result)
            
            print(f"  âœ… å‚æ•°æ•°é‡: {param_count:,}")
            print(f"  â±ï¸ æ„å»ºæ—¶é—´: {build_time:.3f}s")
            print(f"  ğŸƒ è®­ç»ƒæ—¶é—´: {train_time:.3f}s/batch")
            print(f"  ğŸµ ç”Ÿæˆæ—¶é—´: {gen_time:.3f}s")
            
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    return results

def benchmark_device_performance():
    """æµ‹è¯•GPU vs CPUæ€§èƒ½"""
    print("\nâš¡ è®¾å¤‡æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    devices = ['cpu']
    if torch.cuda.is_available():
        devices.append('cuda')
    
    results = {}
    
    for device_name in devices:
        print(f"\nğŸ® æµ‹è¯•è®¾å¤‡: {device_name.upper()}")
        
        device = torch.device(device_name)
        
        # åˆ›å»ºæ¨¡å‹
        generator = HoyoMusicGenerator(
            vocab_size=100,
            seq_length=100,
            embedding_dim=128,
            lstm_units=256
        )
        generator.build_model()
        generator.model.to(device)
        
        # æµ‹è¯•æ•°æ®
        batch_size = 32
        X = np.random.randint(0, 100, (batch_size, 100))
        y = np.random.randint(0, 100, (batch_size,))
        
        # --- ä¿®å¤å…³é”®ï¼šå°†Xå’Œyè½¬ä¸ºå½“å‰deviceä¸Šçš„tensor ---
        X_tensor = torch.LongTensor(X).to(device)
        y_tensor = torch.LongTensor(y).to(device)
        
        # é¢„çƒ­
        for _ in range(5):
            generator.model.train()
            outputs = generator.model(X_tensor)
            loss = generator.criterion(outputs, y_tensor)
            generator.optimizer.zero_grad()
            loss.backward()
            generator.optimizer.step()
        
        # è®­ç»ƒæ€§èƒ½æµ‹è¯•
        start_time = time.time()
        for _ in range(20):
            generator.model.train()
            outputs = generator.model(X_tensor)
            loss = generator.criterion(outputs, y_tensor)
            generator.optimizer.zero_grad()
            loss.backward()
            generator.optimizer.step()
        train_time = (time.time() - start_time) / 20
        
        # ç”Ÿæˆæ€§èƒ½æµ‹è¯•
        seed = np.random.randint(0, 100, 100)
        start_time = time.time()
        for _ in range(10):
            # ç”Ÿæˆæ—¶æ¨¡å‹å·²åœ¨deviceä¸Šï¼Œseedè¾“å…¥è½¬ä¸ºdevice
            current_seq = list(seed[-generator.seq_length:])
            x = torch.LongTensor([current_seq]).to(device)
            with torch.no_grad():
                outputs = generator.model(x)
                predictions = torch.softmax(outputs / 1.0, dim=1).cpu().numpy()[0]
                _ = np.random.choice(len(predictions), p=predictions)
        gen_time = (time.time() - start_time) / 10
        
        results[device_name] = {
            'train_time': train_time,
            'gen_time': gen_time
        }
        
        print(f"  ğŸƒ è®­ç»ƒæ—¶é—´: {train_time:.3f}s/batch")
        print(f"  ğŸµ ç”Ÿæˆæ—¶é—´: {gen_time:.3f}s")
    
    # æ˜¾ç¤ºæ€§èƒ½å¯¹æ¯”
    if 'cuda' in results and 'cpu' in results:
        speedup_train = results['cpu']['train_time'] / results['cuda']['train_time']
        speedup_gen = results['cpu']['gen_time'] / results['cuda']['gen_time']
        print(f"\nğŸ“ˆ GPUåŠ é€Ÿæ•ˆæœ:")
        print(f"  - è®­ç»ƒåŠ é€Ÿ: {speedup_train:.1f}x")
        print(f"  - ç”ŸæˆåŠ é€Ÿ: {speedup_gen:.1f}x")
    
    return results

def benchmark_generation_quality():
    """æµ‹è¯•ä¸åŒæ¸©åº¦å‚æ•°çš„ç”Ÿæˆè´¨é‡"""
    print("\nğŸ¨ ç”Ÿæˆè´¨é‡åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºå°å‹æ¨¡å‹ç”¨äºæµ‹è¯•
    generator = HoyoMusicGenerator(
        vocab_size=50,
        seq_length=50,
        embedding_dim=64,
        lstm_units=128
    )
    generator.build_model()
    
    temperatures = [0.5, 0.8, 1.0, 1.2, 1.5, 2.0]
    results = {}
    
    seed = np.random.randint(0, 50, 50)
    
    for temp in temperatures:
        print(f"ğŸŒ¡ï¸ æµ‹è¯•æ¸©åº¦: {temp}")
        
        sequences = []
        for _ in range(5):
            seq = generator.generate_sequence(seed, length=100, temperature=temp)
            sequences.append(seq)
        
        # è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡
        unique_sequences = len(set(map(tuple, sequences)))
        diversity_score = unique_sequences / len(sequences)
        
        # è®¡ç®—å¹³å‡åºåˆ—é•¿åº¦
        avg_length = np.mean([len(seq) for seq in sequences])
        
        results[temp] = {
            'diversity': diversity_score,
            'avg_length': avg_length,
            'sequences': sequences
        }
        
        print(f"  ğŸ“Š å¤šæ ·æ€§: {diversity_score:.2f}")
        print(f"  ğŸ“ å¹³å‡é•¿åº¦: {avg_length:.1f}")
    
    return results

def save_benchmark_report(model_results, device_results, quality_results):
    """ä¿å­˜åŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
    
    # åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Š
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('HoyoMusic PyTorchæ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š', fontsize=16)
    
    # 1. æ¨¡å‹å¤§å° vs å‚æ•°æ•°é‡
    if model_results:
        names = [r['name'] for r in model_results]
        params = [r['params'] for r in model_results]
        train_times = [r['train_time'] for r in model_results]
        
        ax1.bar(names, params, color='skyblue')
        ax1.set_title('æ¨¡å‹å‚æ•°æ•°é‡å¯¹æ¯”')
        ax1.set_ylabel('å‚æ•°æ•°é‡')
        ax1.tick_params(axis='x', rotation=45)
        
        # 2. è®­ç»ƒæ—¶é—´å¯¹æ¯”
        ax2.bar(names, train_times, color='lightgreen')
        ax2.set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”')
        ax2.set_ylabel('æ—¶é—´(ç§’/batch)')
        ax2.tick_params(axis='x', rotation=45)
    
    # 3. è®¾å¤‡æ€§èƒ½å¯¹æ¯”
    if device_results:
        devices = list(device_results.keys())
        train_times = [device_results[d]['train_time'] for d in devices]
        gen_times = [device_results[d]['gen_time'] for d in devices]
        
        x = np.arange(len(devices))
        width = 0.35
        
        ax3.bar(x - width/2, train_times, width, label='è®­ç»ƒæ—¶é—´', color='orange')
        ax3.bar(x + width/2, gen_times, width, label='ç”Ÿæˆæ—¶é—´', color='purple')
        ax3.set_title('è®¾å¤‡æ€§èƒ½å¯¹æ¯”')
        ax3.set_ylabel('æ—¶é—´(ç§’)')
        ax3.set_xticks(x)
        ax3.set_xticklabels([d.upper() for d in devices])
        ax3.legend()
    
    # 4. æ¸©åº¦ vs å¤šæ ·æ€§
    if quality_results:
        temps = list(quality_results.keys())
        diversity = [quality_results[t]['diversity'] for t in temps]
        
        ax4.plot(temps, diversity, 'ro-', linewidth=2, markersize=8)
        ax4.set_title('æ¸©åº¦å‚æ•° vs ç”Ÿæˆå¤šæ ·æ€§')
        ax4.set_xlabel('æ¸©åº¦')
        ax4.set_ylabel('å¤šæ ·æ€§åˆ†æ•°')
        ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(r'tests/report/pytorch_benchmark_report.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
    with open(r'tests/report/pytorch_benchmark_report.txt', 'w', encoding='utf-8') as f:
        f.write("HoyoMusic PyTorchæ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        
        f.write("æ¨¡å‹å¤§å°æµ‹è¯•ç»“æœ:\n")
        f.write("-" * 30 + "\n")
        for result in model_results:
            f.write(f"{result['name']}æ¨¡å‹:\n")
            f.write(f"  å‚æ•°æ•°é‡: {result['params']:,}\n")
            f.write(f"  è®­ç»ƒæ—¶é—´: {result['train_time']:.3f}s/batch\n")
            f.write(f"  ç”Ÿæˆæ—¶é—´: {result['gen_time']:.3f}s\n\n")
        
        f.write("è®¾å¤‡æ€§èƒ½æµ‹è¯•ç»“æœ:\n")
        f.write("-" * 30 + "\n")
        for device, perf in device_results.items():
            f.write(f"{device.upper()}:\n")
            f.write(f"  è®­ç»ƒæ—¶é—´: {perf['train_time']:.3f}s/batch\n")
            f.write(f"  ç”Ÿæˆæ—¶é—´: {perf['gen_time']:.3f}s\n\n")
        
        f.write("ç”Ÿæˆè´¨é‡æµ‹è¯•ç»“æœ:\n")
        f.write("-" * 30 + "\n")
        for temp, quality in quality_results.items():
            f.write(f"æ¸©åº¦ {temp}:\n")
            f.write(f"  å¤šæ ·æ€§: {quality['diversity']:.2f}\n")
            f.write(f"  å¹³å‡é•¿åº¦: {quality['avg_length']:.1f}\n\n")

def main():
    """ä¸»åŸºå‡†æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ HoyoMusic PyTorchæ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    print(f"ğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯:")
    print(f"  - PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"  - CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"  - GPU: {torch.cuda.get_device_name()}")
        print(f"  - CUDAç‰ˆæœ¬: {torch.version.cuda}")
    
    try:
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        print("\nğŸ”¬ å¼€å§‹åŸºå‡†æµ‹è¯•...")
        
        model_results = benchmark_model_sizes()
        device_results = benchmark_device_performance()
        quality_results = benchmark_generation_quality()
        
        # ä¿å­˜æŠ¥å‘Š
        save_benchmark_report(model_results, device_results, quality_results)
        
        print("\nâœ… åŸºå‡†æµ‹è¯•å®Œæˆï¼")
        print("ğŸ“ æŠ¥å‘Šå·²ä¿å­˜:")
        print("  - å›¾è¡¨æŠ¥å‘Š: pytorch_benchmark_report.png")
        print("  - æ–‡æœ¬æŠ¥å‘Š: pytorch_benchmark_report.txt")
        
    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
